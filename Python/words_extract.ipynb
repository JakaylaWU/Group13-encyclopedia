{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7iVmHcclhGi"
   },
   "source": [
    "# Data description\n",
    "\n",
    "The dataset in this project is mainly plain text files recorded by OCR. The source of OCR is from scanned photos of Encyclopedia Britannica, which was also provided with positional XML files. There was also an inventory CSV file that shows the full title relating to each text file.\n",
    "\n",
    "We decided to use textual data only for this project. There were 155 files of TXT and an inventory CSV file in the text folder. The names of these TXT files are ambiguous and irregular, such as 144850377.txt and 194474782.txt, only by the inventory CSV file we could check their full title. According to the inventory, each edition of Encyclopedia Britannica is separated into numerous files, each representing a section in its book. So the first step we made is to merge files of the same edition manually via an online TXT file merger while deleting the repetitive and unnecessary ones. After the merge process, we have 8 large TXT files of each edition of Encyclopedia Britannica.\n",
    "\n",
    "The Encyclopedia Britannica covers all sorts of human knowledge. Each of its editions was published over a period of time. Compared to 1st (1768–1771), 2nd (1777–1784) and 3rd (1788–1797) editions, later 4th (1801–1810), 5th (1815–1817), and 6th (1820–1823) have covered far more bits of knowledge in greater volumes, and the 7th (1830–1842) and 8th (1853–1860) extends one more volume of books. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project aims to analyze the textual data and find out the changes of a certain topic or knowledge over time. For my part, I chose to analyze how the topic of climate change was reflected during the years first industrial revolution (1760-1840). According to my research, 1860 was the year for the Earth's natural greenhouse effect to be recognized. By 1896, carbon dioxide levels were considered relative to the effect. Lately, in the 1940s and 1950s, the Carbon Dioxide Theory of Climate Change was formulated. It would be interesting to see how people in the era of the first industrial revolution define climate issues and how their concerns shifts over time. The last edition in our dataset was published in the 1850s, so the issue is very likely not widely recognized during the period, but I'm interested in finding some early clues, such as the high use of fossil fuels as well as the record of extreme weather and temperature changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "\n",
    "The best way to achieve the goal is to analyze the frequency of words relating to the climate change topic. Valuable results could be obtained through the visual analysis of the changing keyword frequency in different editions. To do that, I have to do some coding to clean the textual data, do frequency search and output results to a data frame or CSV file for visualization. In the next part, I will show the codes for this process with explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, load the data by opening text files in the encyclopedia folder. The folder includes 8 previously merged text files with the name of each edition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Edition1.txt', 'Edition2.txt', 'Edition3.txt', 'Edition4.txt', 'Edition5.txt', 'Edition6.txt', 'Edition7.txt', 'Edition8.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory of txt files\n",
    "dirs = os.listdir(\"encyclopedia/\")\n",
    "dirs = dirs[1:9]\n",
    "dirs.sort()\n",
    "print(dirs)\n",
    "book_text = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I need to iterate through each text file and extracting informations from them, there are several steps involved in this part. \n",
    "\n",
    "In a for loop, I have to:\n",
    "\n",
    "1. Do text cleaning, including removing line breaks and non-english characters as well as stemming.\n",
    "2. Tokenize each of the text.\n",
    "3. Define a dictionary of keyword sets, they will be used as search keywords while searching through each text set.\n",
    "4. Using the keywords, search their word frequencies in each edition of Encyclopedia Britannica\n",
    "5. Create a dataframe to record search results. The row number +1 represents the edition of the book, and the first column shows the line of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count of Edition1.txt\n",
      "13618679\n",
      "——————— Cleaned sample of Edition1.txt\n",
      "['made', 'with', 'refjpect', 'to', 'mineralogy', 'materia', 'me', 'die', 'a', 'pa', 'thology', 'phyfiology', 'and', 'therapeutics', 'thele', 'are', 'fo', 'interwoven', 'with', 'anatomy', 'botany', 'chemiftry', 'and', 'medicine', 'that', 'in', 'a', 'work', 'of', 'this', 'kind', 'it', 'was', 'almoh', 'impoffible', 'without', 'many', 'none', 'cellary', 'repetitions', 'to', 'treat', 'them', 'as', 'diiiincd', 'fciences', 'indeed', 'properly', 'ipeaking', 'they']\n",
      "\n",
      "Frequency search result in edition 1: \n",
      "{'cholera': 5, 'typhus': 0, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition2.txt\n",
      "54708550\n",
      "——————— Cleaned sample of Edition2.txt\n",
      "['more', 'agreeably', 'inculcated', 'the', 'various', 'topics', 'of', 'art', 'and', 'fcience', 'a', '2', 'have', 'e', 'p', 'r', 'e', 'f', 'a', 'c', 'have', 'been', 'ranged', 'in', 'a', 'fyftematic', 'order', 'and', 'volumes', 'profefledly', 'written', 'upon', 'each', 'but', 'the', 'tafte', 'for', 'novelty', 'ftill', 'demanded', 'various', 'gratification', 'hence', 'un', 'connected', 'mifcellanies', 'and', 'detached', 'efiays', 'appeared']\n",
      "\n",
      "Frequency search result in edition 2: \n",
      "{'cholera': 31, 'typhus': 27, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition3.txt\n",
      "93412912\n",
      "——————— Cleaned sample of Edition3.txt\n",
      "['of', 'what', 'is', 'generally', 'called', 'literature', 'or', 'the', 'knowledge', 'of', 'the', 'languages', 'cuftoms', 'and', 'manners', 'wrhich', 'have', 'prevailed', 'among', 'the', 'various', 'nations', 'of', 'the', 'earth', 'without', 'this', 'knowledge', 'the', 'fcience', 'of', 'the', 'ancients', 'would', 'be', 'locked', 'up', 'from', 'the', 'moderns', 'j', 'and', 'even', 'the', 'difcoveries', 'of', 'modern', 'nations', 'would', 'be']\n",
      "\n",
      "Frequency search result in edition 3: \n",
      "{'cholera': 33, 'typhus': 38, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition4.txt\n",
      "100253682\n",
      "——————— Cleaned sample of Edition4.txt\n",
      "['it', 'acquires', 'a', 'piercing', 'keen', 'n', 'which', 'it', 'retains', 'in', 'its', 'progrefs', 'through', 'warmer', 'climates', 'and', 'is', 'not', 'entirely', 'mitigated', 'until', 'it', 'reach', 'the', 'gulf', 'of', 'mexico', 'over', 'all', 'the', 'continent', 'of', 'north', 'america', 'a', 'northwefterly', 'wind', 'and', 'exceffive', 'cold', 'are', 'lynonymous', 'terms', 'even', 'in', 'the', 'moft', 'fultry', 'weather', 'the']\n",
      "\n",
      "Frequency search result in edition 4: \n",
      "{'cholera': 35, 'typhus': 61, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition5.txt\n",
      "100020287\n",
      "——————— Cleaned sample of Edition5.txt\n",
      "['of', 'glafs', 'contrived', 'to', 'conane', 'living', 'ob', 'jedts', 'fuch', 'as', 'frogs', 'flfties', 'c', 'in', 'order', 'to', 'difeover', 'the', 'circulation', 'of', 'the', 'blood', 'all', 'thefe', 'are', 'contained', 'in', 'a', 'little', 'neat', 'box', 'of', 'flflilkin', 'or', 'mahogany', 'very', 'convenient', 'for', 'carrying', 'in', 'the', 'pocket', 'when', 'an', 'objedl', 'is', 'to', 'be', 'viewed', 'thruft']\n",
      "\n",
      "Frequency search result in edition 5: \n",
      "{'cholera': 35, 'typhus': 69, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition6.txt\n",
      "99972580\n",
      "——————— Cleaned sample of Edition6.txt\n",
      "['preeminence', 'of', 'the', 'method', 'which', 'its', 'compilers', 'have', 'pursued', 'in', 'treating', 'the', 'various', 'branches', 'of', 'the', 'arts', 'and', 'sciences', 'ai1', 'former', 'attempts', 'the', 'alphabet', 'in', 'place', 'of', 'being', 'employed', 'in', 'the', 'hum', 'e', 'unction', 'or', 'an', 'index', 'to', 'the', 'matter', 'contained', 'in', 'the', 'work', 'was', 'made', 'supreme', 'aibiter', 'of', 'the']\n",
      "\n",
      "Frequency search result in edition 6: \n",
      "{'cholera': 36, 'typhus': 62, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition7.txt\n",
      "122287239\n",
      "——————— Cleaned sample of Edition7.txt\n",
      "['served', 'as', 'the', 'groundwork', 'of', 'this', 'more', 'extensive', 'undertaking', 'in', 'which', 'he', 'professedly', 'aimed', 'at', 'the', 'formation', 'of', 'a', 'complete', 'encyclopaedia', 'it', 'consists', 'of', 'thirtyfive', 'books', 'of', 'which', 'the', 'fiist', 'four', 'contain', 'an', 'explanation', 'of', 'the', 'nature', 'of', 'the', 'various', 'subjects', 'discussed', 'in', 'the', 'rest', 'then', 'follow', 'successively', 'six', 'on']\n",
      "\n",
      "Frequency search result in edition 7: \n",
      "{'cholera': 23, 'typhus': 11, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition8.txt\n",
      "129812194\n",
      "——————— Cleaned sample of Edition8.txt\n",
      "['artifices', 'of', 'style', 'with', 'which', 'the', 'genius', 'of', 'the', 'french', 'language', 'enables', 'a', 'skilful', 'writer', 'to', 'smooth', 'and', 'varnish', 'over', 'his', 'most', 'illogical', 'transitions', 'the', 'most', 'essential', 'imperfections', 'however', 'of', 'this', 'historical', 'sketch', 'may', 'he', 'fairly', 'ascribed', 'to', 'a', 'certain', 'vagueness', 'and', 'indecision', 'in', 'the', 'au', 'thor', 's', 'idea', 'with']\n",
      "\n",
      "Frequency search result in edition 8: \n",
      "{'cholera': 110, 'typhus': 26, 'diphtheria': 1, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate the directory and open txts\n",
    "index = 0\n",
    "for file in dirs:\n",
    "    if file.endswith(\".txt\"):\n",
    "        f = open(\"encyclopedia/\" + file,\"r\",encoding = \"utf_8\")\n",
    "        book_text = f.read()\n",
    "\n",
    "        # Clean the text \n",
    "        # Removing line breaks\n",
    "        book_text = book_text.replace(\"-\", \"\").lower()\n",
    "        # Remove all non-english character\n",
    "        book_text = re.sub(\"[^a-zA-Z0-9]+\", \" \", book_text)\n",
    "        # Stemming\n",
    "        lancaster_stem = LancasterStemmer()\n",
    "        lancaster_stem.stem(book_text)\n",
    "        print(\"Total word count of \"+ file)\n",
    "        print(len(book_text))\n",
    "        # Tokenize the text\n",
    "        clean_text = book_text.split()\n",
    "\n",
    "        # Print some of the text to see if it is loaded successfully\n",
    "        print(\"——————— Cleaned sample of \" + file)\n",
    "        print(clean_text[800:850])\n",
    "    \n",
    "        # Define keywords and search keyword frequencies\n",
    "        dic = {\"cholera\":0,\"typhus\":0,\"diphtheria\":0,\"silicosis\":0,\"pneumoconiosis\":0}\n",
    "\n",
    "        # Search keyword frequencies in the text\n",
    "        for word in clean_text:\n",
    "            if word in dic:\n",
    "        \n",
    "                dic[word] = dic[word] + 1\n",
    "        clean_text = ''\n",
    "\n",
    "        print(\"\\nFrequency search result in edition \" + str(index+1) + \": \")\n",
    "        print(dic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Add the frequency result to the dataframe\n",
    "        if(index == 0):\n",
    "            # Create the first line of the dataframe\n",
    "            df = pd.DataFrame(data=dic, index = [index])\n",
    "        else:\n",
    "            # Convert the current line of dictionary values to an list\n",
    "            values = dic.values()\n",
    "            values_list = list(values)\n",
    "            # Add the line to the dataframe\n",
    "            df.loc[index] = values_list\n",
    "        index += 1\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have a dataframe of word frequency with rows representing each edition and columns representing each words. For convenience, we also save the dataframe as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final output dataframe:\n",
      "  edition  cholera  typhus  diphtheria  silicosis  pneumoconiosis\n",
      "0       1        5       0           0          0               0\n",
      "1       2       31      27           0          0               0\n",
      "2       3       33      38           0          0               0\n",
      "3       4       35      61           0          0               0\n",
      "4       5       35      69           0          0               0\n",
      "5       6       36      62           0          0               0\n",
      "6       7       23      11           0          0               0\n",
      "7       8      110      26           1          0               0\n"
     ]
    }
   ],
   "source": [
    "# Add the Edition column at the first position\n",
    "df.insert(0, 'edition', ['1', '2', '3', '4', '5', '6', '7', '8'])\n",
    "# Output result\n",
    "print(\"\\n Final output dataframe:\")\n",
    "print(df)\n",
    "df.to_csv(\"output_word_proportion_.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the results, it is now possible to analyze distributions of keyword frequencies and relationships between them. Since most of the values appear upward trend, using line charts mainly to show their evolution will be a good visualization method.\n",
    "\n",
    "For the first plot, I chose to visualize the words relating to climate change and natural disasters, to see if the trend of climate change was recorded during the publication of Encyclopedia Britannica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'climate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'climate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fy/3g82983d0yv7yf87_7c6vb280000gn/T/ipykernel_93020/1698519154.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_theme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"darkgrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'climate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'climate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplot1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"edition of the book\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'number of occurrences'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplot1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency of words relating to climate change and natural disasters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'climate'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df.index = df['edition']\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "plot1 = sns.lineplot(data=df['climate'], label='climate')\n",
    "plot1.set(xlabel = \"edition of the book\", ylabel='number of occurrences')\n",
    "plot1.set_title('Frequency of words relating to climate change and natural disasters')\n",
    "plot2 = sns.lineplot(data=df['temperature'], label='temperature')\n",
    "plot3 = sns.lineplot(data=df['hazard'], label='hazard')\n",
    "plot4 = sns.lineplot(data=df['disaster'], label='disaster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the appearance of relevant terms did increase over time. Notably, the terms \"climate\" and \"temperature\" both increased their frequency rapidly in a similar trend. It is possible that they often appear in same contexts in the books.\n",
    "\n",
    "For the second plot, I want to know if climate change's impact on living creatures was noticed and recorded. The result is shown in the second plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "plot1 = sns.lineplot(data=df['animal'], label='animal')\n",
    "plot1.set(xlabel = \"edition of the book\", ylabel='number of occurrences')\n",
    "plot1.set_title('Frequency of words relating to biodiversity')\n",
    "plot2 = sns.lineplot(data=df['plant'], label='plant')\n",
    "plot3 = sns.lineplot(data=df['extinct'], label='extinct')\n",
    "plot3 = sns.lineplot(data=df['diminish'], label='diminish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the term \"animal\" and \"plant\" increased over time, the word \"extinct\" and \"diminsh\" appeared more frequently in late editions. \n",
    "\n",
    "Next, I want to visualize the trend of the first energy revolution. Since the main source of energy during the first industiral revolution was fossil energy, the apperace of words relating to energy should be increasing. For this part, I chose to use both line plot and stacked area plot. In the output, the lines will represent conceptual words relating to energy while the stacked part will represent physical energy sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = df[['coal','gas','fuel']].plot.area()\n",
    "plot1.set(xlabel = \"edition of the book\", ylabel='number of occurrences')\n",
    "plot1.set_title('Frequency of words relating to energy')\n",
    "plot3 = sns.lineplot(data=df['energy'], label='energy', color='r')\n",
    "plot2 = sns.lineplot(data=df['carbon'], label='carbon', color='k')\n",
    "plot4 = sns.lineplot(data=df['emission'], label='emission', color = 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that there was massive use of energy and it is likely the use of these energy sources increased the appearence of \"carbon\". The next question will be: did these books record what emission of greenhouse gases had brought to their environment. The results are shown in the next plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "plot1 = sns.lineplot(data=df['atmosphere'], label='atmosphere')\n",
    "plot1.set(xlabel = \"edition of the book\", ylabel='number of occurrences')\n",
    "plot1.set_title('Frequency of words relating to greenhouse effects')\n",
    "plot2 = sns.lineplot(data=df['atmospheric'], label='atmospheric')\n",
    "plot3 = sns.lineplot(data=df['sealevel'], label='sealevel')\n",
    "plot4 = sns.lineplot(data=df['greenhouse'], label='greenhouse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the trend shows an upward trend, the arisen of some term frequencies seems abrupt, which is not suitable for drawing obvious conclusions.\n",
    "\n",
    "Lastly, I want to know whether there was an early awareness of the environmental protection, and whether this awareness was strengthened before the emergence of climate change theories. The visualized result was shown in the final plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "plot1 = sns.lineplot(data=df['environment'], label='environment')\n",
    "plot1.set(xlabel = \"edition of the book\", ylabel='number of occurrences')\n",
    "plot1.set_title('Frequency of words relating to environmental protection')\n",
    "plot2 = sns.lineplot(data=df['protection'], label='protection')\n",
    "plot3 = sns.lineplot(data=df['preservation'], label='preservation')\n",
    "plot4 = sns.lineplot(data=df['conservation'], label='conservation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect and Hypothesise\n",
    "\n",
    "Based on the information in the plots, I made the following observation: \n",
    "\n",
    "1. The trend of climate change and its increasing effects are shown in the publishment of Encyclopedia Britannica.\n",
    "\n",
    "2. The additions of \"animal\" and \"plant\" parallel with another trend, which is the decrease of biodiversity.\n",
    "\n",
    "3. The books recorded the increase in energy consumption and carbon emission during the boom of the first industrial revolution.\n",
    "\n",
    "4. The concerns of terms relating to the greenhouse effect increased rapidly after the publishment of the fifth edition, which was from 1815 to 1817.\n",
    "\n",
    "5. Words relating to environmental protection has shown a good increasing trend in the latter editions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflecting the results, three hypotheses are proposed:\n",
    "\n",
    "1. Although the theory of climate warming did not emerge before the 1900s, people in earlier periods had noticed and were concerned relating trends.\n",
    "\n",
    "2. Increasing trend of natural disasters and species extinction has warned the people of the time. \n",
    "\n",
    "3. The awareness of environmental protection has begun to take root before the advent of climate change theories.\n",
    "\n",
    "The first hypothesis mainly comes from observations 1 and 4. However, instead of just using word frequencies in encyclopedias, studying at more contemporary sources such as reports and weather records will make this hypothesis more convincing. The second hypothesis is from observation 2 and divergent thinking through the first hypothesis. Although more animals and plants are added in the book (which is natural considering the increasing volumes), the tally of extinct species seems to be growing. Nevertheless, just the frequency of the word \"extinction\" and \"diminish\" is not enough to prove this hypothesis, if the text can be further processed and extract terms that contain more than one words, such as \"endangered animal\", the hypothesis can be test further.\n",
    "\n",
    "The third hypothesis might be the most convincible one, considering the appearance of words relating to environmental protection clearly increased in the middle and late industrial revolution (5th to 8th edition of the encyclopedias). Moreover, from previous research, 1860 was the for the Earth's natural greenhouse effect to be recognized, right after the publishment of the 8th edition. It can be assumed that the growing awareness of environmental protection has prompted people to do relevant research. To further test this hypothesis, it will be necessary to study more relevant publications around the first fifty years of the 1800s.\n",
    "\n",
    "Overall, the conducted word frequency analysis did provide meaningful results and interesting hypotheses but the data processing is rather rough. The hypotheses can be further analyzed by advanced methods. In addition to the methods mentioned above, the textual data provide could be further analyzed through spelling correction, more stemming, and even Natural Language Processing (NLP)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment_1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "aef91eb63a643aab461427778578dd9926cf9bf3fa93b4e669e8b6e9913c0ced"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
