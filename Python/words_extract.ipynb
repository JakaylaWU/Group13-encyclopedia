{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7iVmHcclhGi"
   },
   "source": [
    "# Data description\n",
    "\n",
    "The dataset in this project is mainly plain text files recorded by OCR. The source of OCR is from scanned photos of Encyclopedia Britannica, which was also provided with positional XML files. There was also an inventory CSV file that shows the full title relating to each text file.\n",
    "\n",
    "We decided to use textual data only for this project. There were 155 files of TXT and an inventory CSV file in the text folder. The names of these TXT files are ambiguous and irregular, such as 144850377.txt and 194474782.txt, only by the inventory CSV file we could check their full title. According to the inventory, each edition of Encyclopedia Britannica is separated into numerous files, each representing a section in its book. So the first step we made is to merge files of the same edition manually via an online TXT file merger while deleting the repetitive and unnecessary ones. After the merge process, we have 8 large TXT files of each edition of Encyclopedia Britannica.\n",
    "\n",
    "The Encyclopedia Britannica covers all sorts of human knowledge. Each of its editions was published over a period of time. Compared to 1st (1768–1771), 2nd (1777–1784) and 3rd (1788–1797) editions, later 4th (1801–1810), 5th (1815–1817), and 6th (1820–1823) have covered far more bits of knowledge in greater volumes, and the 7th (1830–1842) and 8th (1853–1860) extends one more volume of books. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project aims to analyze the textual data and find out the changes of a certain topic or knowledge over time. For my part, I chose to analyze how the topic of climate change was reflected during the years first industrial revolution (1760-1840). According to my research, 1860 was the year for the Earth's natural greenhouse effect to be recognized. By 1896, carbon dioxide levels were considered relative to the effect. Lately, in the 1940s and 1950s, the Carbon Dioxide Theory of Climate Change was formulated. It would be interesting to see how people in the era of the first industrial revolution define climate issues and how their concerns shifts over time. The last edition in our dataset was published in the 1850s, so the issue is very likely not widely recognized during the period, but I'm interested in finding some early clues, such as the high use of fossil fuels as well as the record of extreme weather and temperature changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "\n",
    "The best way to achieve the goal is to analyze the frequency of words relating to the climate change topic. Valuable results could be obtained through the visual analysis of the changing keyword frequency in different editions. To do that, I have to do some coding to clean the textual data, do frequency search and output results to a data frame or CSV file for visualization. In the next part, I will show the codes for this process with explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, load the data by opening text files in the encyclopedia folder. The folder includes 8 previously merged text files with the name of each edition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Edition1.txt', 'Edition2.txt', 'Edition3.txt', 'Edition4.txt', 'Edition5.txt', 'Edition6.txt', 'Edition7.txt', 'Edition8.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory of txt files\n",
    "dirs = os.listdir(\"encyclopedia/\")\n",
    "dirs = dirs[1:9]\n",
    "dirs.sort()\n",
    "print(dirs)\n",
    "book_text = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I need to iterate through each text file and extracting informations from them, there are several steps involved in this part. \n",
    "\n",
    "In a for loop, I have to:\n",
    "\n",
    "1. Do text cleaning, including removing line breaks and non-english characters as well as stemming.\n",
    "2. Tokenize each of the text.\n",
    "3. Define a dictionary of keyword sets, they will be used as search keywords while searching through each text set.\n",
    "4. Using the keywords, search their word frequencies in each edition of Encyclopedia Britannica\n",
    "5. Create a dataframe to record search results. The row number +1 represents the edition of the book, and the first column shows the line of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count of Edition1.txt\n",
      "13618679\n",
      "——————— Cleaned sample of Edition1.txt\n",
      "['made', 'with', 'refjpect', 'to', 'mineralogy', 'materia', 'me', 'die', 'a', 'pa', 'thology', 'phyfiology', 'and', 'therapeutics', 'thele', 'are', 'fo', 'interwoven', 'with', 'anatomy', 'botany', 'chemiftry', 'and', 'medicine', 'that', 'in', 'a', 'work', 'of', 'this', 'kind', 'it', 'was', 'almoh', 'impoffible', 'without', 'many', 'none', 'cellary', 'repetitions', 'to', 'treat', 'them', 'as', 'diiiincd', 'fciences', 'indeed', 'properly', 'ipeaking', 'they']\n",
      "\n",
      "Frequency search result in edition 1: \n",
      "{'cholera': 5, 'typhus': 0, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition2.txt\n",
      "54708550\n",
      "——————— Cleaned sample of Edition2.txt\n",
      "['more', 'agreeably', 'inculcated', 'the', 'various', 'topics', 'of', 'art', 'and', 'fcience', 'a', '2', 'have', 'e', 'p', 'r', 'e', 'f', 'a', 'c', 'have', 'been', 'ranged', 'in', 'a', 'fyftematic', 'order', 'and', 'volumes', 'profefledly', 'written', 'upon', 'each', 'but', 'the', 'tafte', 'for', 'novelty', 'ftill', 'demanded', 'various', 'gratification', 'hence', 'un', 'connected', 'mifcellanies', 'and', 'detached', 'efiays', 'appeared']\n",
      "\n",
      "Frequency search result in edition 2: \n",
      "{'cholera': 31, 'typhus': 27, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition3.txt\n",
      "93412912\n",
      "——————— Cleaned sample of Edition3.txt\n",
      "['of', 'what', 'is', 'generally', 'called', 'literature', 'or', 'the', 'knowledge', 'of', 'the', 'languages', 'cuftoms', 'and', 'manners', 'wrhich', 'have', 'prevailed', 'among', 'the', 'various', 'nations', 'of', 'the', 'earth', 'without', 'this', 'knowledge', 'the', 'fcience', 'of', 'the', 'ancients', 'would', 'be', 'locked', 'up', 'from', 'the', 'moderns', 'j', 'and', 'even', 'the', 'difcoveries', 'of', 'modern', 'nations', 'would', 'be']\n",
      "\n",
      "Frequency search result in edition 3: \n",
      "{'cholera': 33, 'typhus': 38, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition4.txt\n",
      "100253682\n",
      "——————— Cleaned sample of Edition4.txt\n",
      "['it', 'acquires', 'a', 'piercing', 'keen', 'n', 'which', 'it', 'retains', 'in', 'its', 'progrefs', 'through', 'warmer', 'climates', 'and', 'is', 'not', 'entirely', 'mitigated', 'until', 'it', 'reach', 'the', 'gulf', 'of', 'mexico', 'over', 'all', 'the', 'continent', 'of', 'north', 'america', 'a', 'northwefterly', 'wind', 'and', 'exceffive', 'cold', 'are', 'lynonymous', 'terms', 'even', 'in', 'the', 'moft', 'fultry', 'weather', 'the']\n",
      "\n",
      "Frequency search result in edition 4: \n",
      "{'cholera': 35, 'typhus': 61, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition5.txt\n",
      "100020287\n",
      "——————— Cleaned sample of Edition5.txt\n",
      "['of', 'glafs', 'contrived', 'to', 'conane', 'living', 'ob', 'jedts', 'fuch', 'as', 'frogs', 'flfties', 'c', 'in', 'order', 'to', 'difeover', 'the', 'circulation', 'of', 'the', 'blood', 'all', 'thefe', 'are', 'contained', 'in', 'a', 'little', 'neat', 'box', 'of', 'flflilkin', 'or', 'mahogany', 'very', 'convenient', 'for', 'carrying', 'in', 'the', 'pocket', 'when', 'an', 'objedl', 'is', 'to', 'be', 'viewed', 'thruft']\n",
      "\n",
      "Frequency search result in edition 5: \n",
      "{'cholera': 35, 'typhus': 69, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition6.txt\n",
      "99972580\n",
      "——————— Cleaned sample of Edition6.txt\n",
      "['preeminence', 'of', 'the', 'method', 'which', 'its', 'compilers', 'have', 'pursued', 'in', 'treating', 'the', 'various', 'branches', 'of', 'the', 'arts', 'and', 'sciences', 'ai1', 'former', 'attempts', 'the', 'alphabet', 'in', 'place', 'of', 'being', 'employed', 'in', 'the', 'hum', 'e', 'unction', 'or', 'an', 'index', 'to', 'the', 'matter', 'contained', 'in', 'the', 'work', 'was', 'made', 'supreme', 'aibiter', 'of', 'the']\n",
      "\n",
      "Frequency search result in edition 6: \n",
      "{'cholera': 36, 'typhus': 62, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition7.txt\n",
      "122287239\n",
      "——————— Cleaned sample of Edition7.txt\n",
      "['served', 'as', 'the', 'groundwork', 'of', 'this', 'more', 'extensive', 'undertaking', 'in', 'which', 'he', 'professedly', 'aimed', 'at', 'the', 'formation', 'of', 'a', 'complete', 'encyclopaedia', 'it', 'consists', 'of', 'thirtyfive', 'books', 'of', 'which', 'the', 'fiist', 'four', 'contain', 'an', 'explanation', 'of', 'the', 'nature', 'of', 'the', 'various', 'subjects', 'discussed', 'in', 'the', 'rest', 'then', 'follow', 'successively', 'six', 'on']\n",
      "\n",
      "Frequency search result in edition 7: \n",
      "{'cholera': 23, 'typhus': 11, 'diphtheria': 0, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n",
      "Total word count of Edition8.txt\n",
      "129812194\n",
      "——————— Cleaned sample of Edition8.txt\n",
      "['artifices', 'of', 'style', 'with', 'which', 'the', 'genius', 'of', 'the', 'french', 'language', 'enables', 'a', 'skilful', 'writer', 'to', 'smooth', 'and', 'varnish', 'over', 'his', 'most', 'illogical', 'transitions', 'the', 'most', 'essential', 'imperfections', 'however', 'of', 'this', 'historical', 'sketch', 'may', 'he', 'fairly', 'ascribed', 'to', 'a', 'certain', 'vagueness', 'and', 'indecision', 'in', 'the', 'au', 'thor', 's', 'idea', 'with']\n",
      "\n",
      "Frequency search result in edition 8: \n",
      "{'cholera': 110, 'typhus': 26, 'diphtheria': 1, 'silicosis': 0, 'pneumoconiosis': 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate the directory and open txts\n",
    "index = 0\n",
    "for file in dirs:\n",
    "    if file.endswith(\".txt\"):\n",
    "        f = open(\"encyclopedia/\" + file,\"r\",encoding = \"utf_8\")\n",
    "        book_text = f.read()\n",
    "\n",
    "        # Clean the text \n",
    "        # Removing line breaks\n",
    "        book_text = book_text.replace(\"-\", \"\").lower()\n",
    "        # Remove all non-english character\n",
    "        book_text = re.sub(\"[^a-zA-Z0-9]+\", \" \", book_text)\n",
    "        # Stemming\n",
    "        lancaster_stem = LancasterStemmer()\n",
    "        lancaster_stem.stem(book_text)\n",
    "        print(\"Total word count of \"+ file)\n",
    "        print(len(book_text))\n",
    "        # Tokenize the text\n",
    "        clean_text = book_text.split()\n",
    "\n",
    "        # Print some of the text to see if it is loaded successfully\n",
    "        print(\"——————— Cleaned sample of \" + file)\n",
    "        print(clean_text[800:850])\n",
    "    \n",
    "        # Define keywords and search keyword frequencies\n",
    "        dic = {\"cholera\":0,\"typhus\":0,\"diphtheria\":0,\"silicosis\":0,\"pneumoconiosis\":0}\n",
    "\n",
    "        # Search keyword frequencies in the text\n",
    "        for word in clean_text:\n",
    "            if word in dic:\n",
    "        \n",
    "                dic[word] = dic[word] + 1\n",
    "        clean_text = ''\n",
    "\n",
    "        print(\"\\nFrequency search result in edition \" + str(index+1) + \": \")\n",
    "        print(dic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Add the frequency result to the dataframe\n",
    "        if(index == 0):\n",
    "            # Create the first line of the dataframe\n",
    "            df = pd.DataFrame(data=dic, index = [index])\n",
    "        else:\n",
    "            # Convert the current line of dictionary values to an list\n",
    "            values = dic.values()\n",
    "            values_list = list(values)\n",
    "            # Add the line to the dataframe\n",
    "            df.loc[index] = values_list\n",
    "        index += 1\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have a dataframe of word frequency with rows representing each edition and columns representing each words. For convenience, we also save the dataframe as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final output dataframe:\n",
      "  edition  cholera  typhus  diphtheria  silicosis  pneumoconiosis\n",
      "0       1        5       0           0          0               0\n",
      "1       2       31      27           0          0               0\n",
      "2       3       33      38           0          0               0\n",
      "3       4       35      61           0          0               0\n",
      "4       5       35      69           0          0               0\n",
      "5       6       36      62           0          0               0\n",
      "6       7       23      11           0          0               0\n",
      "7       8      110      26           1          0               0\n"
     ]
    }
   ],
   "source": [
    "# Add the Edition column at the first position\n",
    "df.insert(0, 'edition', ['1', '2', '3', '4', '5', '6', '7', '8'])\n",
    "# Output result\n",
    "print(\"\\n Final output dataframe:\")\n",
    "print(df)\n",
    "df.to_csv(\"output_word_proportion_.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment_1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "aef91eb63a643aab461427778578dd9926cf9bf3fa93b4e669e8b6e9913c0ced"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
